{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'item_id': '123373', 'waist': '29', 'size': 7, 'quality': 5, 'cup size': 'd', 'hips': '38', 'bra size': '34', 'category': 'new', 'bust': '36', 'height': '5ft 6in', 'user_name': 'Emily', 'length': 'just right', 'fit': 'small', 'user_id': '991571'}, {'item_id': '123373', 'waist': '31', 'size': 13, 'quality': 3, 'cup size': 'b', 'hips': '30', 'bra size': '36', 'category': 'new', 'length': 'just right', 'height': '5ft 2in', 'user_name': 'sydneybraden2001', 'fit': 'small', 'user_id': '587883'}, {'item_id': '123373', 'waist': '30', 'size': 7, 'quality': 2, 'cup size': 'b', 'shoe size': '9.00', 'bra size': '32', 'category': 'new', 'length': 'slightly long', 'height': '5ft 7in', 'user_name': 'Ugggh', 'fit': 'small', 'user_id': '395665'}, {'item_id': '123373', 'category': 'new', 'size': 21, 'quality': 5, 'user_name': 'alexmeyer626', 'length': 'just right', 'fit': 'fit', 'cup size': 'dd/e', 'user_id': '875643'}, {'item_id': '123373', 'category': 'new', 'size': 18, 'quality': 5, 'user_name': 'dberrones1', 'length': 'slightly long', 'fit': 'small', 'bra size': '36', 'cup size': 'b', 'user_id': '944840', 'height': '5ft 2in'}, {'item_id': '123373', 'waist': '27', 'size': 11, 'quality': 5, 'cup size': 'c', 'hips': '41', 'bra size': '36', 'category': 'new', 'length': 'just right', 'height': '5ft 4in', 'user_name': 'Doreenajane', 'fit': 'small', 'user_id': '162012'}, {'item_id': '123373', 'waist': '26', 'size': 5, 'quality': 1, 'cup size': 'b', 'bra size': '32', 'category': 'new', 'length': 'just right', 'height': '5ft 3in', 'user_name': 'barbiejenks', 'fit': 'large', 'user_id': '114843'}, {'item_id': '123373', 'shoe size': '8.50', 'size': 11, 'quality': 5, 'cup size': 'd', 'hips': '42.0', 'bra size': '38', 'category': 'new', 'length': 'just right', 'height': '5ft 5in', 'user_name': 'brettloie', 'fit': 'small', 'user_id': '58869'}, {'item_id': '123373', 'shoe size': '11.00', 'size': 30, 'quality': 4, 'shoe width': 'wide', 'cup size': 'd', 'hips': '50.0', 'bra size': '42', 'category': 'new', 'length': 'just right', 'height': '5ft 10in', 'user_name': 'francescaviola', 'fit': 'small', 'user_id': '279568'}, {'item_id': '123373', 'shoe size': '9.00', 'size': 13, 'quality': 5, 'cup size': 'dd/e', 'hips': '41.0', 'bra size': '36', 'category': 'new', 'bust': '39', 'height': '5ft 6in', 'user_name': 'laurenpolzin', 'length': 'just right', 'fit': 'fit', 'user_id': '950172'}]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from urllib.request import urlopen\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import random\n",
    "import copy\n",
    "import gzip\n",
    "import json\n",
    "import string\n",
    "\n",
    "def parseData(fname):\n",
    "    for l in open(fname):\n",
    "        yield eval(l)\n",
    "def feature_label(data):\n",
    "    return data[\"fit\"]\n",
    "def feature_X(data,encoding):\n",
    "    hotencoding=encoding[catID[data['category']]]\n",
    "    return [1,data['height'],data['weight'],int(data['rating'])]+hotencoding\n",
    "def str_to_inch(s):\n",
    "    s = s.replace('\\\"', '')\n",
    "    height=s.split(\"\\'\")\n",
    "    return int(height[0])*12+int(height[1])\n",
    "def str_to_weight(s):\n",
    "    s = s.replace('lbs', '')\n",
    "    return int(s)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_data = list(parseData(\"modcloth_final_data.json\"))\n",
    "#random.shuffle(data)\n",
    "print(test_data[:10])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'dress': 72894, 'down': 387, 'gown': 34445, 'sheath': 15189, 'top': 3923, 'shift': 4136, 'maxi': 2678, 'skirt': 1241, 'jumpsuit': 4159, 'sweater': 948, 'romper': 2517, 'jacket': 1909, 'mini': 1438, 'blazer': 633, 'cardigan': 203, 'pant': 85, 'blouson': 11, 'coat': 792, 'tank': 145, 'blouse': 504, 'shirtdress': 583, 'ballgown': 13, 'hoodie': 11, 'kimono': 24, 'pullover': 46, 'culottes': 163, 'vest': 222, 'turtleneck': 23, 'shirt': 220, 'pants': 340, 'frock': 170, 'trouser': 50, 'tunic': 137, 'suit': 108, 'parka': 13, 'bomber': 103, 'legging': 81, 'sweatshirt': 104, 'midi': 46, 'jeans': 4, 'duster': 12, 'poncho': 34, 't-shirt': 11, 'leggings': 95, 'peacoat': 33, 'print': 90, 'cami': 12, 'knit': 42, 'culotte': 60, 'overalls': 6, 'sweatershirt': 3, 'cape': 69, 'tee': 20, 'trousers': 12, 'caftan': 4, 'skort': 4, 'for': 5, 'jogger': 4, 'skirts': 5, 'trench': 20, 'kaftan': 13, 'combo': 8, 'henley': 7, 'tight': 13, 'sweatpants': 1, 'crewneck': 1, 'buttondown': 1, 'overcoat': 1})\n"
     ]
    }
   ],
   "source": [
    "#SET UP CATEGORY FOR data\n",
    "categoryCounts = defaultdict(int)\n",
    "for d in data1:\n",
    "    categoryCounts[d['category']] += 1\n",
    "categories = [c for c in categoryCounts]\n",
    "catID = dict(zip(list(categories),range(len(categories))))\n",
    "print(categoryCounts)\n",
    "\n",
    "hot_encoding={}                                        #hot encoding of 0-41\n",
    "for i in range(len(categories)):\n",
    "    encoding=[0]*len(categories)\n",
    "    encoding[i]=1\n",
    "    hot_encoding[i]=encoding\n",
    "    \n",
    "#print(hot_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TruePos(pred,y,label):\n",
    "    res=0\n",
    "    for pred_, y_ in zip(pred, y):\n",
    "        if pred_ == y_ and y_== label:\n",
    "            \n",
    "            res+=1\n",
    "    return res\n",
    "\n",
    "def FalsePos(pred,y,label):\n",
    "    res=0\n",
    "    for pred_, y_ in zip(pred, y):\n",
    "        if pred_ == label and  y_ != label:\n",
    "            \n",
    "            res+=1\n",
    "    return res\n",
    "\n",
    "def TrueNeg(pred,y,label):\n",
    "    res=0\n",
    "    for pred_, y_ in zip(pred, y):\n",
    "        if  pred_ != label and label != y_:\n",
    "            \n",
    "                res+=1\n",
    "    return res\n",
    "\n",
    "def FalseNeg(pred,y,label):\n",
    "    res=0\n",
    "    for pred_, y_ in zip(pred, y):\n",
    "        if label!= pred_ and y_==label:\n",
    "            \n",
    "            res+=1\n",
    "    return res\n",
    "def BER(pred,train_y,label):\n",
    "    TP=TruePos(pred,train_y,label)\n",
    "    FP=FalsePos(pred,train_y,label)\n",
    "    TN=TrueNeg(pred,train_y,label)\n",
    "    FN=FalseNeg(pred,train_y,label)\n",
    "    TPR= TP/(TP+FN)\n",
    "    TNR= TN/(TN+FP)\n",
    "    FPR= FP/(FP+TN)\n",
    "    FNR=FN/(FN+TP)\n",
    "    #BER= 1-0.5*(TPR+TNR)\n",
    "    BER= 0.5*(FPR+FNR)\n",
    "    print(\"Number of time predicted\",label,\" correct :\", TP)\n",
    "    print(\"Number of time predicted\",label,\" Wrong :\", FP)\n",
    "    print(\"Number of time predicted different than actual\",label,\"  :\", FN)\n",
    "    \n",
    "    print(\"TPR \",label,\" is :\", TPR)\n",
    "    print(\"TNR \",label,\" is :\", TNR)\n",
    "    print(\"TPR \",label,\" is :\", TPR)\n",
    "    print(\"FPR \",label,\" is :\", FPR)\n",
    "    print(\"BER \",label,\" is :\", BER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = open('renttherunway_final_data.json', \"r\")\n",
    "data = list([json.loads(line) for line in open('renttherunway_final_data.json', 'r')])\n",
    "    \n",
    "data1=[]\n",
    "data_test=[]\n",
    "for i in data:\n",
    "    if 'weight' in i and 'bust size' in i and 'height' in i and 'rating' in i and 'review_text' in i:\n",
    "        if i['rating'] != None:\n",
    "            i['weight']=str_to_weight(i['weight'])\n",
    "            i['height']=str_to_inch(i['height'])\n",
    "            data1.append(i)\n",
    "\n",
    "for i in test_data:\n",
    "    if 'weight' in i and 'bust size' in i and 'height' in i and 'rating' in i and 'review_text' in i:\n",
    "        i['weight']=str_to_weight(i['weight'])\n",
    "        i['height']=str_to_inch(i['height'])\n",
    "        data_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 82790\n",
      "136152 15132 151284\n"
     ]
    }
   ],
   "source": [
    "#print(len(data_train),len(data))\n",
    "print(len(data_test),len(test_data))    #different data sets cannot be test with training set\n",
    "\n",
    "random.shuffle(data1)\n",
    "data_train=data1[:len(data1)//10*9]\n",
    "data_test=data1[len(data1)//10*9:]\n",
    "print(len(data_train),len(data_test),len(data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "fit : fit\n",
      "user_id : 420272\n",
      "bust size : 34d\n",
      "item_id : 2260466\n",
      "weight : 137\n",
      "rating : 10\n",
      "rented for : vacation\n",
      "review_text : An adorable romper! Belt and zipper were a little hard to navigate in a full day of wear/bathroom use, but that's to be expected. Wish it had pockets, but other than that-- absolutely perfect! I got a million compliments.\n",
      "body type : hourglass\n",
      "review_summary : So many compliments!\n",
      "category : romper\n",
      "height : 68\n",
      "size : 14\n",
      "age : 28\n",
      "review_date : April 20, 2016\n"
     ]
    }
   ],
   "source": [
    "print(type(data[0]))\n",
    "for key in data[0]:\n",
    "    print(key,':',data[0][key])\n",
    "\n",
    "\n",
    "\n",
    "string1= \"5'8\\\"\"\n",
    "#print(data_train[1]['height'])\n",
    "#print(str_to_inch(data_train[1]['height']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {})\n"
     ]
    }
   ],
   "source": [
    "#print(test_data[:1])\n",
    "#l=[feature_height(d) for d in data_train]\n",
    "dic= defaultdict(int)\n",
    "#print(l[0])\n",
    "#for i in l:                                       #num of fit/small/large\n",
    "#    j=str(i)\n",
    "#    dic[j]+=1\n",
    "\n",
    "p=[d['category'] for d in data_train]             #num of items per category\n",
    "#for i in p:\n",
    "#    j=str(i)\n",
    "#    dic[j]+=1\n",
    "    \n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#possible missing values:\n",
    "\n",
    "#bust size\n",
    "#weight\n",
    "#rating\n",
    "#review_text\n",
    "#height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPeritem = defaultdict(set)\n",
    "itemPerUser = defaultdict(set)\n",
    "for d in data:\n",
    "    user,item = d['user_id'], d['item_id']\n",
    "    usersPeritem[item].add(user)\n",
    "    itemPerUser[user].add(item)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in itemPerUser:\n",
    "   # print(len(itemPerUser[i]))\n",
    "#print(len(itemPerUser))          #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[feature_X(d,hot_encoding) for d in data_train]\n",
    "X_test=[feature_X(d,hot_encoding) for d in data_test]\n",
    "\n",
    "Y_train=[feature_label(d) for d in data_train]\n",
    "Y_test=[feature_label(d) for d in data_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = linear_model.LogisticRegression(C=2.0,)\n",
    "mod.fit(X_train, Y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy feature:weight,height,rating 0.7336769759450171\n",
      "done..\n"
     ]
    }
   ],
   "source": [
    "pred_valid= mod.predict(X_test)\n",
    "correct1 = pred_valid==Y_test\n",
    "\n",
    "print(\"accuracy feature:weight,height,rating\", sum(correct1)/len(correct1))\n",
    "#print(len(correct1))\n",
    "print('done..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR  fit for training set is : 0.990996668767444\n",
      "TNR  fit for training set is : 0.04720496894409938\n",
      "TPR  fit for training set is : 0.990996668767444\n",
      "FPR  fit for training set is : 0.9527950310559006\n",
      "BER  fit for training set is : 0.4808991811442283\n",
      "TPR  large for training set is : 0.019278299555116164\n",
      "TNR  large for training set is : 0.9948890075520634\n",
      "TPR  large for training set is : 0.019278299555116164\n",
      "FPR  large for training set is : 0.0051109924479365324\n",
      "BER  large for training set is : 0.4929163464464102\n",
      "TPR  small for training set is : 0.027972027972027972\n",
      "TNR  small for training set is : 0.9902513328255903\n",
      "TPR  small for training set is : 0.027972027972027972\n",
      "FPR  small for training set is : 0.009748667174409748\n",
      "BER  small for training set is : 0.49088831960119084\n"
     ]
    }
   ],
   "source": [
    "BER(pred_valid,Y_test,'fit')\n",
    "BER(pred_valid,Y_test,'large')\n",
    "BER(pred_valid,Y_test,'small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'fit': 14842, 'large': 106, 'small': 184}) defaultdict(<class 'int'>, {'fit': 11107, 'large': 2023, 'small': 2002})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dic1= defaultdict(int)\n",
    "dic2=defaultdict(int)\n",
    "\n",
    "#print(l[0])\n",
    "for i in pred_valid:                                       #num of fit/small/large\n",
    "    j=str(i)\n",
    "    dic1[j]+=1\n",
    "for i in Y_test:                                       #num of fit/small/large\n",
    "    j=str(i)\n",
    "    dic2[j]+=1\n",
    "    \n",
    "print(dic1,dic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(Y_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fit', 'fit', 'fit', 'fit', 'fit']\n"
     ]
    }
   ],
   "source": [
    "print([feature_label(d) for d in data_train[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try bag of words methods\n",
    "sp = set(string.punctuation)\n",
    "wordCount = defaultdict(int)\n",
    "for d in data1:\n",
    "    r = ''.join([c for c in d['review_text'].lower() if not c in sp])\n",
    "    tokens = r.split()\n",
    "    for w in tokens:\n",
    "        wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44034\n"
     ]
    }
   ],
   "source": [
    "print(len(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done..\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "word_num = len(counts)//10\n",
    "words = [x[1] for x in counts[:word_num]]\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words(\"english\")\n",
    "filterword = [w for w in words if not w in stopwords]\n",
    "#filterword = [w for w in words]\n",
    "wordId = dict(zip(filterword, range(len(filterword))))\n",
    "wordSet = set(filterword)\n",
    "word_df = dict(zip(filterword, [0]*(len(filterword))))\n",
    "\n",
    "for d in data1:\n",
    "    r = ''.join([c for c in d['review_text'].lower() if not c in sp])\n",
    "    tokens = r.split()\n",
    "    sets= set(tokens)\n",
    "    for i in sets:\n",
    "        if i in filterword:\n",
    "            word_df[i]+=1\n",
    "print('done..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "word_df1= copy.deepcopy(word_df)\n",
    "N=len(data1)\n",
    "for i in word_df1:\n",
    "    word_df1[i]= math.log(N/word_df1[i])\n",
    "#print(word_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done..\n"
     ]
    }
   ],
   "source": [
    "def feature1(datum):\n",
    "    feat = [0]*len(filterword)\n",
    "    r = ''.join([c for c in datum['review_text'].lower() if not c in sp])\n",
    "    tokens = r.split()\n",
    "    for w in tokens:\n",
    "        if w in wordSet:\n",
    "            feat[wordId[w]] += 1\n",
    "    sets=set(tokens)\n",
    "    for s in sets:\n",
    "        if s in wordSet:\n",
    "            feat[wordId[s]]=feat[wordId[s]]*word_df1[s]\n",
    "\n",
    "    feat.append(1)\n",
    "    return feat\n",
    "\n",
    "nf1 = len(feature1(data1[0]))\n",
    "\n",
    "X1 = lil_matrix((len(data1), nf1))\n",
    "\n",
    "for i in range(len(data1)):\n",
    "    \n",
    "    x = feature1(data1[i])\n",
    "    for j in range(nf1):\n",
    "        if x[j]:\n",
    "            X1[i,j] = x[j]\n",
    "\n",
    "print('done..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy feature:bag of words idf 0.7922283901665345\n",
      "done..\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "Xtrain1 = X1[:len(data1)//10*9]\n",
    "\n",
    "Xtest1 = X1[len(data1)//10*9:]\n",
    "\n",
    "\n",
    "\n",
    "mod_ifdif = linear_model.LogisticRegression(C=2.0,random_state=0)\n",
    "mod_ifdif.fit(Xtrain1, Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy feature:bag of words idf 0.7922283901665345\n",
      "done..\n",
      "done\n",
      "Number of time predicted fit  correct : 10474\n",
      "Number of time predicted fit  Wrong : 2308\n",
      "Number of time predicted different than actual fit   : 633\n",
      "TPR  fit  is : 0.9430089132979202\n",
      "TNR  fit  is : 0.426583850931677\n",
      "TPR  fit  is : 0.9430089132979202\n",
      "FPR  fit  is : 0.573416149068323\n",
      "BER  fit  is : 0.31520361788520135\n",
      "Number of time predicted large  correct : 812\n",
      "Number of time predicted large  Wrong : 410\n",
      "Number of time predicted different than actual large   : 1211\n",
      "TPR  large  is : 0.4013840830449827\n",
      "TNR  large  is : 0.9687237775574034\n",
      "TPR  large  is : 0.4013840830449827\n",
      "FPR  large  is : 0.03127622244259669\n",
      "BER  large  is : 0.31494606969880695\n",
      "Number of time predicted small  correct : 702\n",
      "Number of time predicted small  Wrong : 426\n",
      "Number of time predicted different than actual small   : 1300\n",
      "TPR  small  is : 0.35064935064935066\n",
      "TNR  small  is : 0.9675552170601676\n",
      "TPR  small  is : 0.35064935064935066\n",
      "FPR  small  is : 0.032444782939832446\n",
      "BER  small  is : 0.3408977161452409\n"
     ]
    }
   ],
   "source": [
    "pred_valid2= mod_ifdif.predict(Xtest1)\n",
    "correct2 = pred_valid2==Y_test\n",
    "print(\"accuracy feature:bag of words idf\", sum(correct2)/len(correct2))\n",
    "\n",
    "\n",
    "#print(len(correct1))\n",
    "print('done..')\n",
    "print('done')\n",
    "\n",
    "BER(pred_valid2,Y_test,'fit')\n",
    "BER(pred_valid2,Y_test,'large')\n",
    "BER(pred_valid2,Y_test,'small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'fit': 12782, 'large': 1222, 'small': 1128}) defaultdict(<class 'int'>, {'fit': 11107, 'large': 2023, 'small': 2002})\n"
     ]
    }
   ],
   "source": [
    "dic1= defaultdict(int)\n",
    "dic2=defaultdict(int)\n",
    "\n",
    "#print(l[0])\n",
    "for i in pred_valid1:                                       #num of fit/small/large\n",
    "    j=str(i)\n",
    "    dic1[j]+=1\n",
    "for i in Y_test:                                       #num of fit/small/large\n",
    "    j=str(i)\n",
    "    dic2[j]+=1\n",
    "    \n",
    "print(dic1,dic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'fit': 10474, 'large': 812, 'predict small but wrong': 426, 'predicted large but wrong': 410, 'predict fit but wrong': 2308, 'small': 702})\n"
     ]
    }
   ],
   "source": [
    "##i fdif result\n",
    "dic1= defaultdict(int)\n",
    "dic2=defaultdict(int)\n",
    "dic3=defaultdict(int)\n",
    "for i,j in zip(pred_valid1,Y_test):\n",
    "    if(i==j and i =='small'):\n",
    "        dic1[i]+=1\n",
    "    elif (i==j and i =='large'):\n",
    "        dic1[i]+=1\n",
    "    elif(i==j and i =='fit'):\n",
    "        dic1[i]+=1\n",
    "    elif(i=='small'):\n",
    "        dic1['predict small but wrong']+=1\n",
    "    elif(i=='large'):\n",
    "        dic1['predicted large but wrong']+=1\n",
    "    else:\n",
    "        dic1['predict fit but wrong']+=1\n",
    "print(dic1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done..\n"
     ]
    }
   ],
   "source": [
    "def feature(datum):\n",
    "    hotencoding=hot_encoding[catID[datum['category']]]\n",
    "    feat = [0]*len(filterword)\n",
    "    r = ''.join([c for c in datum['review_text'].lower() if not c in sp])\n",
    "    tokens = r.split()\n",
    "    for w in tokens:\n",
    "        if w in wordSet:\n",
    "            feat[wordId[w]] += 1\n",
    "    #feat.append(datum['height'])\n",
    "    #feat.append(datum['weight'])\n",
    "    \n",
    "    feat.append(datum['rating'])\n",
    "    feat= feat+hotencoding\n",
    "    feat.append(1)\n",
    "    return feat\n",
    "\n",
    "nf = len(feature(data1[0]))\n",
    "\n",
    "X = lil_matrix((len(data1), nf))\n",
    "\n",
    "for i in range(len(data1)):\n",
    "    \n",
    "    x = feature(data1[i])\n",
    "    for j in range(nf):\n",
    "        if x[j]:\n",
    "            X[i,j] = x[j]\n",
    "\n",
    "print('done..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if(X!=X1):\n",
    "#    print(\"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "Xtrain = X[:len(data1)//10*9]\n",
    "\n",
    "Xtest = X[len(data1)//10*9:]\n",
    "\n",
    "\n",
    "\n",
    "mod1 = linear_model.LogisticRegression(C=2.0,class_weight='balanced')\n",
    "mod1.fit(Xtrain, Y_train)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy feature:bag of words 0.6987179487179487\n",
      "Number of time predicted fit  correct : 7911\n",
      "Number of time predicted fit  Wrong : 844\n",
      "Number of time predicted different than actual fit   : 3196\n",
      "TPR  fit  is : 0.7122535338075088\n",
      "TNR  fit  is : 0.7903105590062112\n",
      "TPR  fit  is : 0.7122535338075088\n",
      "FPR  fit  is : 0.20968944099378883\n",
      "BER  fit  is : 0.24871795359314003\n",
      "Number of time predicted large  correct : 1306\n",
      "Number of time predicted large  Wrong : 1799\n",
      "Number of time predicted different than actual large   : 717\n",
      "TPR  large  is : 0.6455758774097874\n",
      "TNR  large  is : 0.8627660385994355\n",
      "TPR  large  is : 0.6455758774097874\n",
      "FPR  large  is : 0.13723396140056449\n",
      "BER  large  is : 0.24582904199538852\n",
      "Number of time predicted small  correct : 1356\n",
      "Number of time predicted small  Wrong : 1916\n",
      "Number of time predicted different than actual small   : 646\n",
      "TPR  small  is : 0.6773226773226774\n",
      "TNR  small  is : 0.8540746382330541\n",
      "TPR  small  is : 0.6773226773226774\n",
      "FPR  small  is : 0.14592536176694593\n",
      "BER  small  is : 0.2343013422221343\n",
      "done..\n"
     ]
    }
   ],
   "source": [
    "pred_valid3= mod1.predict(Xtest)\n",
    "correct3 = pred_valid3==Y_test\n",
    "#BER(pred_valid,Y_test)\n",
    "print(\"accuracy feature:bag of words\", sum(correct3)/len(correct3))\n",
    "BER(pred_valid3,Y_test,'fit')\n",
    "BER(pred_valid3,Y_test,'large')\n",
    "BER(pred_valid3,Y_test,'small')\n",
    "#print(len(correct1))\n",
    "print('done..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FP=FalsePos(pred_valid,Y_test)\n",
    "#print(pred_valid,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy feature:bag of words 0.6987179487179487\n",
      "done..\n"
     ]
    }
   ],
   "source": [
    "pred_valid= mod1.predict(Xtest)\n",
    "correct2 = pred_valid==Y_test\n",
    "print(\"accuracy feature:bag of words\", sum(correct2)/len(correct2))\n",
    "#print(len(correct1))\n",
    "print('done..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy feature:bag of words 0.6987179487179487\n",
      "done..\n"
     ]
    }
   ],
   "source": [
    "pred_valid= mod1.predict(Xtest)\n",
    "correct2 = pred_valid==Y_test\n",
    "print(\"accuracy feature:bag of words\", sum(correct2)/len(correct2))\n",
    "#print(len(correct1))\n",
    "print('done..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy feature:bag of words 0.6987179487179487\n",
      "done..\n"
     ]
    }
   ],
   "source": [
    "pred_valid= mod1.predict(Xtest)\n",
    "correct2 = pred_valid==Y_test\n",
    "print(\"accuracy feature:bag of words\", sum(correct2)/len(correct2))\n",
    "#print(len(correct1))\n",
    "print('done..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy feature:bag of words 0.6987179487179487\n",
      "done..\n"
     ]
    }
   ],
   "source": [
    "pred_valid= mod1.predict(Xtest)\n",
    "correct2 = pred_valid==Y_test\n",
    "print(\"accuracy feature:bag of words\", sum(correct2)/len(correct2))\n",
    "#print(len(correct1))\n",
    "print('done..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy feature:bag of words 0.6987179487179487\n",
      "done..\n"
     ]
    }
   ],
   "source": [
    "pred_valid= mod1.predict(Xtest)\n",
    "correct2 = pred_valid==Y_test\n",
    "print(\"accuracy feature:bag of words\", sum(correct2)/len(correct2))\n",
    "#print(len(correct1))\n",
    "print('done..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy feature:bag of words 0.6987179487179487\n",
      "done..\n"
     ]
    }
   ],
   "source": [
    "pred_valid= mod1.predict(Xtest)\n",
    "correct2 = pred_valid==Y_test\n",
    "print(\"accuracy feature:bag of words\", sum(correct2)/len(correct2))\n",
    "#print(len(correct1))\n",
    "print('done..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy feature:bag of words 0.6987179487179487\n",
      "done..\n"
     ]
    }
   ],
   "source": [
    "pred_valid= mod1.predict(Xtest)\n",
    "correct2 = pred_valid==Y_test\n",
    "print(\"accuracy feature:bag of words\", sum(correct2)/len(correct2))\n",
    "#print(len(correct1))\n",
    "print('done..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'fit': 8755, 'large': 3105, 'small': 3272}) defaultdict(<class 'int'>, {'fit': 11107, 'large': 2023, 'small': 2002})\n"
     ]
    }
   ],
   "source": [
    "dic1= defaultdict(int)\n",
    "dic2=defaultdict(int)\n",
    "\n",
    "#print(l[0])\n",
    "for i in pred_valid:                                       #num of fit/small/large\n",
    "    j=str(i)\n",
    "    dic1[j]+=1\n",
    "for i in Y_test:                                       #num of fit/small/large\n",
    "    j=str(i)\n",
    "    dic2[j]+=1\n",
    "    \n",
    "print(dic1,dic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic1= defaultdict(int)\n",
    "dic2=defaultdict(int)\n",
    "dic3=defaultdict(int)\n",
    "for i,j in zip(pred_valid,Y_test):\n",
    "    if(i==j and i =='small'):\n",
    "        dic1[i]+=1\n",
    "    elif (i==j and i =='large'):\n",
    "        dic1[i]+=1\n",
    "    elif(i==j and i =='fit'):\n",
    "        dic1[i]+=1\n",
    "    elif(i=='small'):\n",
    "        dic1['predict small but wrong']+=1\n",
    "    elif(i=='large'):\n",
    "        dic1['predicted large but wrong']+=1\n",
    "    else:\n",
    "        dic1['predict fit but wrong']+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'fit': 7911, 'large': 1306, 'predict small but wrong': 1916, 'predicted large but wrong': 1799, 'predict fit but wrong': 844, 'small': 1356}) defaultdict(<class 'int'>, {})\n"
     ]
    }
   ],
   "source": [
    "print(dic1,dic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
